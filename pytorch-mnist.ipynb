{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task\n",
    "Our task is simple, recognize handwritten digits. We will use MNIST dataset for this tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary library\n",
    "In this tutorial, we are going to use pytorch, the cutting-edge deep learning framework to complete our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataloader, in PyTorch, we feed the trainer data with use of dataloader\n",
    "## We create dataloader with dataset from torchvision, \n",
    "## and we dont have to download it seperately, all automatically done\n",
    "\n",
    "# Define batch size, batch size is how much data you feed for training in one iteration\n",
    "batch_size_train = 1024 # We use a small batch size here for training\n",
    "batch_size_test = 1024 #\n",
    "\n",
    "# define how image transformed\n",
    "image_transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])\n",
    "#image datasets\n",
    "train_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                           train=True, \n",
    "                                           download=True,\n",
    "                                           transform=image_transform)\n",
    "test_dataset = torchvision.datasets.MNIST('dataset/', \n",
    "                                          train=False, \n",
    "                                          download=True,\n",
    "                                          transform=image_transform)\n",
    "#data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=batch_size_test, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import library\n",
    "import matplotlib.pyplot as plt\n",
    "# We can check the dataloader\n",
    "_, (example_datas, labels) = next(enumerate(test_loader))\n",
    "sample = example_datas[0][0]\n",
    "# show the data\n",
    "plt.imshow(sample, cmap='gray', interpolation='none')\n",
    "print(\"Label: \"+ str(labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: dataset/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "torch.Size([1024, 1, 28, 28])\n",
      "tensor([[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,  2.5542,  2.3251,\n",
      "          0.5686, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.6632,  2.8088,  2.8088,\n",
      "          2.6942,  2.4524,  1.3832, -0.0933, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242,  1.0141,  2.8088,  2.8088,  2.8088,\n",
      "          2.8088,  2.8088,  2.8088,  2.5669,  0.2249, -0.3988, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242,  0.9886,  2.5287,  2.8088,  2.8088,  2.4142,\n",
      "          1.3959,  2.0196,  2.8088,  2.8088,  2.3251, -0.2587, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.0169,  2.5924,  2.8088,  2.8088,  1.4596, -0.2842,\n",
      "         -0.4242,  0.0722,  2.6942,  2.8088,  2.4778, -0.1569, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242,  0.2504,  2.7706,  2.8088,  1.0650, -0.3606, -0.4242,\n",
      "         -0.4242, -0.4242,  2.2105,  2.8088,  2.8088,  0.0467, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242,  0.5304,  1.2686, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242,  1.7650,  2.8088,  2.8088,  0.4922, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.0551,  2.5669,  2.8088,  2.3760,  0.2249, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242,  0.8995,  2.8088,  2.8088,  0.9377, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.0551,  2.2105,  2.8088,  2.4015, -0.3478, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "          0.5431,  2.8215,  2.8088,  2.4142, -0.3478, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3224,\n",
      "          0.0595,  1.7523,  2.4524,  2.4524,  2.0069,  0.9632, -0.3606,  0.0467,\n",
      "          2.5542,  2.8088,  2.7706,  0.6322, -0.4115, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4115,  0.0595,  2.1469,\n",
      "          2.8088,  2.8088,  2.8088,  2.8088,  2.8088,  2.8088,  2.1723,  2.6433,\n",
      "          2.8088,  2.5542,  0.8995, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.8613,  2.8088,  2.8088,\n",
      "          2.7324,  1.8414,  1.3959,  2.3124,  2.8088,  2.8088,  2.8088,  2.8088,\n",
      "          2.8088,  1.0523, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.1442,  2.4906,  2.8088,  2.5797,\n",
      "          0.5686, -0.4242, -0.4242,  0.1231,  2.4906,  2.8088,  2.8088,  2.8088,\n",
      "          2.0832, -0.1315, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242,  1.0523,  2.8088,  2.3760,  0.2504,\n",
      "         -0.1187, -0.1824,  1.2432,  2.5033,  2.8088,  2.8088,  2.8088,  2.8088,\n",
      "          2.8088,  1.5359, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242,  1.2559,  2.8088,  2.5160,  1.8541,\n",
      "          2.6306,  2.8088,  2.8088,  2.8088,  2.8088,  1.4214,  2.1596,  2.8088,\n",
      "          2.8088,  2.6306,  0.4031, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242,  0.4413,  2.6433,  2.8088,  2.8088,\n",
      "          2.8088,  2.8088,  2.3760,  1.9432, -0.0042, -0.4242, -0.1824,  2.1087,\n",
      "          2.8088,  2.8088,  2.5797,  0.3013,  0.5940, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.0042,  1.5996,  2.2233,\n",
      "          1.2432,  1.2432, -0.1824, -0.4242, -0.4242, -0.4242, -0.4242, -0.1824,\n",
      "          2.0451,  2.7833,  2.8088,  2.8088,  1.7650, -0.2460, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242,  2.1342,  2.7197,  1.5996, -0.0424, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242],\n",
      "        [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
      "         -0.4242, -0.4242, -0.4242, -0.4242]])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset)\n",
    "print(example_datas.shape)\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we can start to build our CNN model\n",
    "## We first import the pytorch nn module and optimizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "## Simple NN\n",
    "# Definir el modelo simple\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 50)  # Capa oculta con 50 neuronas\n",
    "        self.fc2 = nn.Linear(50, 10)     # Capa de salida con 10 neuronas\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "## Comples CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #input channel 1, output channel 10\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1)\n",
    "        #input channel 10, output channel 20\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1)\n",
    "        #dropout layer\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        #fully connected layer\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create model and optimizer\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "device = \"cpu\"\n",
    "model = CNN().to(device) # using cpu here\n",
    "# model = SimpleNN().to(device) # using cpu here\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "##define train function\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval=10000):\n",
    "    model.train()\n",
    "    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n",
    "    counter = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(tk0):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "        pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n",
    "    writer.add_scalar(\"Accuracy/train\", correct, epoch)\n",
    "\n",
    "##define test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    writer.add_scalar(\"Accuracy/test\", correct, epoch)\n",
    "\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plopezme\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b27808af2044da6976857d4f4bbf877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plopezme\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:47: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0492, Accuracy: 3691/10000 (37%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d902f623288846118066d896e55a6c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 1.4448, Accuracy: 5533/10000 (55%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ee38f27b0944d799a634888e7f3024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.9621, Accuracy: 7057/10000 (71%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff081975f07491abec4b0c1a2d357db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.7299, Accuracy: 7732/10000 (77%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3666d43e64da408dbca81adbf55792f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6174, Accuracy: 8154/10000 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch =5\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 28, 28))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
